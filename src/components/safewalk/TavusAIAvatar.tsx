import React, { useState, useEffect, useRef } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import { 
  Video, 
  VideoOff, 
  Mic, 
  MicOff, 
  Volume2, 
  VolumeX,
  Settings,
  AlertCircle,
  CheckCircle,
  Loader,
  Phone,
  PhoneOff,
  Brain,
  Heart,
  MapPin,
  Clock
} from 'lucide-react';
import { useAuth } from '../../contexts/AuthContext';
import { supabase } from '../../lib/supabase';

interface TavusAIAvatarProps {
  isActive: boolean;
  onEmergencyDetected: () => void;
  roomToken?: string;
  onConnectionStatusChange?: (status: 'connecting' | 'connected' | 'disconnected' | 'error') => void;
}

interface LiveKitConnection {
  room: any;
  localParticipant: any;
  remoteParticipants: Map<string, any>;
}

interface ApiKeys {
  livekit_api_key: string;
  livekit_api_secret: string;
  livekit_ws_url: string;
  tavus_api_key: string;
  elevenlabs_api_key?: string;
  deepgram_api_key?: string;
  gemini_api_key: string;
}

export function TavusAIAvatar({ 
  isActive, 
  onEmergencyDetected, 
  roomToken,
  onConnectionStatusChange 
}: TavusAIAvatarProps) {
  const { user } = useAuth();
  const [connectionStatus, setConnectionStatus] = useState<'connecting' | 'connected' | 'disconnected' | 'error'>('disconnected');
  const [isVideoEnabled, setIsVideoEnabled] = useState(true);
  const [isAudioEnabled, setIsAudioEnabled] = useState(true);
  const [isMuted, setIsMuted] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [avatarSpeaking, setAvatarSpeaking] = useState(false);
  const [conversation, setConversation] = useState<Array<{id: string, type: 'user' | 'avatar', content: string, timestamp: number}>>([]);
  const [inputText, setInputText] = useState('');
  const [apiKeys, setApiKeys] = useState<ApiKeys | null>(null);
  const [loadingKeys, setLoadingKeys] = useState(true);
  const [tavusSession, setTavusSession] = useState<any>(null);
  const [livekitRoom, setLivekitRoom] = useState<any>(null);

  const videoRef = useRef<HTMLVideoElement>(null);
  const avatarVideoRef = useRef<HTMLVideoElement>(null);
  const livekitConnectionRef = useRef<LiveKitConnection | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  useEffect(() => {
    if (isActive) {
      loadApiKeysFromDatabase();
    } else {
      disconnectFromRoom();
    }

    return () => {
      disconnectFromRoom();
    };
  }, [isActive]);

  useEffect(() => {
    if (apiKeys && isActive) {
      initializeTavusLiveKitConnection();
    }
  }, [apiKeys, isActive]);

  useEffect(() => {
    onConnectionStatusChange?.(connectionStatus);
  }, [connectionStatus, onConnectionStatusChange]);

  useEffect(() => {
    scrollToBottom();
  }, [conversation]);

  const loadApiKeysFromDatabase = async () => {
    if (!user) return;

    setLoadingKeys(true);
    try {
      const { data, error } = await supabase
        .from('user_api_keys')
        .select('*')
        .eq('user_id', user.id)
        .maybeSingle();

      if (error) {
        console.error('Error loading API keys:', error);
        setConnectionStatus('error');
        return;
      }

      if (!data) {
        console.log('No API keys found for user');
        setConnectionStatus('error');
        return;
      }

      // Validate required keys
      if (!data.livekit_api_key || !data.livekit_api_secret || !data.livekit_ws_url || !data.tavus_api_key || !data.gemini_api_key) {
        console.log('Missing required API keys');
        setConnectionStatus('error');
        return;
      }

      setApiKeys({
        livekit_api_key: data.livekit_api_key,
        livekit_api_secret: data.livekit_api_secret,
        livekit_ws_url: data.livekit_ws_url,
        tavus_api_key: data.tavus_api_key,
        elevenlabs_api_key: data.elevenlabs_api_key,
        deepgram_api_key: data.deepgram_api_key,
        gemini_api_key: data.gemini_api_key
      });

      console.log('API keys loaded successfully');
    } catch (error) {
      console.error('Error loading API keys:', error);
      setConnectionStatus('error');
    } finally {
      setLoadingKeys(false);
    }
  };

  const initializeTavusLiveKitConnection = async () => {
    if (!apiKeys) return;

    setConnectionStatus('connecting');
    
    try {
      console.log('Initializing Tavus + LiveKit connection...');
      
      // Step 1: Create Tavus avatar with p5d11710002a persona
      const avatarSession = await createTavusAvatarSession();
      if (!avatarSession) {
        throw new Error('Failed to create Tavus avatar session');
      }
      
      setTavusSession(avatarSession);
      
      // Step 2: Connect to LiveKit room
      await connectToLiveKitRoom(avatarSession.room_name);
      
      setConnectionStatus('connected');
      addAvatarMessage("Hello! I'm your SafeMate AI companion with the p5d11710002a persona. I'm here to keep you safe and provide emotional support. How are you feeling today?");
      
    } catch (error) {
      console.error('Failed to initialize Tavus + LiveKit:', error);
      setConnectionStatus('error');
    }
  };

  const createTavusAvatarSession = async () => {
    if (!apiKeys) return null;

    try {
      console.log('Creating Tavus avatar session with p5d11710002a persona...');
      
      // Create conversation with Tavus API using p5d11710002a persona
      const response = await fetch('https://tavusapi.com/v2/conversations', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKeys.tavus_api_key}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          persona_id: 'p5d11710002a', // Your specific persona ID
          conversation_name: `SafeMate Session ${Date.now()}`,
          callback_url: null, // Optional webhook URL
          properties: {
            max_call_duration: 3600, // 1 hour max
            participant_left_timeout: 300, // 5 minutes
            participant_absent_timeout: 60, // 1 minute
            enable_recording: false, // Set to true if you want recordings
            enable_transcription: true,
            language: 'en'
          },
          conversation_context: "You are SafeMate, an AI safety companion. You're currently in a video call with a user who needs safety monitoring and emotional support. Be caring, protective, and supportive. Watch for any signs of distress or danger.",
          custom_greeting: "Hi! I'm your SafeMate AI companion. I'm here to keep you safe and provide support. How are you feeling right now?"
        })
      });

      if (!response.ok) {
        const errorData = await response.json();
        console.error('Tavus API error:', errorData);
        throw new Error(`Tavus API error: ${response.status} - ${errorData.message || 'Unknown error'}`);
      }

      const data = await response.json();
      console.log('Tavus session created:', data);
      
      return {
        conversation_id: data.conversation_id,
        conversation_url: data.conversation_url,
        room_name: data.conversation_id, // Use conversation ID as room name
        status: data.status
      };
      
    } catch (error) {
      console.error('Error creating Tavus avatar session:', error);
      throw error;
    }
  };

  const connectToLiveKitRoom = async (roomName: string) => {
    if (!apiKeys) return;

    try {
      console.log('Connecting to LiveKit room:', roomName);
      
      // Generate LiveKit token (this would normally be done server-side)
      const token = await generateLiveKitToken(roomName);
      
      // In a real implementation, you would use the LiveKit SDK here
      // For now, we'll simulate the connection
      await simulateLiveKitConnection(roomName, token);
      
      setLivekitRoom({ roomName, token });
      console.log('Connected to LiveKit room successfully');
      
    } catch (error) {
      console.error('Error connecting to LiveKit room:', error);
      throw error;
    }
  };

  const generateLiveKitToken = async (roomName: string): Promise<string> => {
    // In production, this should be done server-side for security
    // This is a placeholder implementation
    
    console.log('Generating LiveKit token for room:', roomName);
    
    // You would use the LiveKit server SDK here:
    // const token = new AccessToken(apiKeys.livekit_api_key, apiKeys.livekit_api_secret, {
    //   identity: user?.id || 'user',
    //   ttl: '1h'
    // });
    // token.addGrant({ roomJoin: true, room: roomName });
    // return token.toJwt();
    
    return `lk_token_${roomName}_${user?.id}_${Date.now()}`;
  };

  const simulateLiveKitConnection = async (roomName: string, token: string) => {
    // Simulate connection delay
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    console.log('Simulated LiveKit connection established');
    
    // In a real implementation, this would:
    // 1. Connect to LiveKit room using the WebSocket URL
    // 2. Set up local video/audio tracks
    // 3. Handle remote participant events
    // 4. Integrate with Tavus avatar video stream
  };

  const disconnectFromRoom = () => {
    if (livekitConnectionRef.current) {
      // Cleanup LiveKit connection
      livekitConnectionRef.current = null;
    }
    
    if (tavusSession) {
      // End Tavus conversation
      endTavusSession();
    }
    
    setConnectionStatus('disconnected');
    setTavusSession(null);
    setLivekitRoom(null);
  };

  const endTavusSession = async () => {
    if (!tavusSession || !apiKeys) return;

    try {
      await fetch(`https://tavusapi.com/v2/conversations/${tavusSession.conversation_id}/end`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKeys.tavus_api_key}`,
          'Content-Type': 'application/json'
        }
      });
      
      console.log('Tavus session ended');
    } catch (error) {
      console.error('Error ending Tavus session:', error);
    }
  };

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  };

  const addAvatarMessage = (content: string) => {
    const message = {
      id: Date.now().toString(),
      type: 'avatar' as const,
      content,
      timestamp: Date.now()
    };
    
    setConversation(prev => [...prev, message]);
    
    // Simulate avatar speaking
    setAvatarSpeaking(true);
    setTimeout(() => setAvatarSpeaking(false), content.length * 50);
  };

  const addUserMessage = (content: string) => {
    const message = {
      id: Date.now().toString(),
      type: 'user' as const,
      content,
      timestamp: Date.now()
    };
    
    setConversation(prev => [...prev, message]);
  };

  const handleUserInput = async (text: string) => {
    addUserMessage(text);
    
    // Process with Gemini 2.5 Flash API
    try {
      const response = await getGeminiResponse(text);
      addAvatarMessage(response);
    } catch (error) {
      console.error('Error getting Gemini response:', error);
      addAvatarMessage("I'm having trouble processing that right now, but I'm still here to help keep you safe.");
    }
  };

  const getGeminiResponse = async (userInput: string): Promise<string> => {
    if (!apiKeys?.gemini_api_key) {
      throw new Error('Gemini API key not available');
    }

    // Emergency detection
    const emergencyKeywords = ['help', 'emergency', 'danger', 'scared', 'unsafe', 'threat', 'attack', 'stranger', 'following', 'lost'];
    if (emergencyKeywords.some(keyword => userInput.toLowerCase().includes(keyword))) {
      onEmergencyDetected();
      return "üö® I detected you might be in danger! I'm immediately alerting your emergency contacts and activating all safety protocols. Stay calm, help is on the way. Keep talking to me - I'm here with you and monitoring everything.";
    }

    try {
      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${apiKeys.gemini_api_key}`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          contents: [{
            parts: [{
              text: `You are SafeMate, an AI safety companion with the p5d11710002a persona. You're currently in a video call with a user who needs safety monitoring and emotional support. You can see them through the video feed and should be caring, protective, and supportive.

Recent conversation context: ${conversation.slice(-5).map(m => `${m.type}: ${m.content}`).join('\n')}

User just said: "${userInput}"

Respond as a caring AI video companion who can see the user and prioritizes their safety and emotional well-being. Keep responses conversational, supportive, and acknowledge that you can see them. If you detect any safety concerns, prioritize those immediately.`
            }]
          }],
          generationConfig: {
            temperature: 0.7,
            topK: 40,
            topP: 0.95,
            maxOutputTokens: 200,
          },
          safetySettings: [
            {
              category: "HARM_CATEGORY_HARASSMENT",
              threshold: "BLOCK_MEDIUM_AND_ABOVE"
            },
            {
              category: "HARM_CATEGORY_HATE_SPEECH",
              threshold: "BLOCK_MEDIUM_AND_ABOVE"
            }
          ]
        }),
      });

      if (!response.ok) {
        throw new Error(`Gemini API error: ${response.status}`);
      }

      const data = await response.json();
      
      if (data.candidates && data.candidates[0] && data.candidates[0].content) {
        return data.candidates[0].content.parts[0].text;
      } else {
        throw new Error('Invalid response from Gemini API');
      }
    } catch (error) {
      console.error('Error calling Gemini 2.5 Flash API:', error);
      
      // Fallback responses
      const fallbackResponses = [
        "I can see you're doing well! I'm here monitoring your safety through our video connection. How can I help support you right now?",
        "Thanks for sharing that with me! I can see you through the video and I'm here to keep you safe. What's on your mind?",
        "I'm watching over you through our video call and everything looks good. You're safe with me. How are you feeling?",
        "I can see you clearly and you're doing great! I'm here to provide support and keep you safe. What would you like to talk about?"
      ];
      
      return fallbackResponses[Math.floor(Math.random() * fallbackResponses.length)];
    }
  };

  const sendMessage = () => {
    if (inputText.trim()) {
      handleUserInput(inputText);
      setInputText('');
    }
  };

  const startVoiceInput = () => {
    setIsListening(true);
    console.log('Starting voice input with Deepgram integration...');
    // In production, this would use Deepgram for speech recognition
  };

  const stopVoiceInput = () => {
    setIsListening(false);
    console.log('Stopping voice input...');
  };

  const toggleMute = () => {
    setIsMuted(!isMuted);
    // This would mute/unmute the LiveKit audio track
  };

  const toggleVideo = () => {
    setIsVideoEnabled(!isVideoEnabled);
    // This would enable/disable the LiveKit video track
  };

  if (!isActive) {
    return null;
  }

  if (loadingKeys) {
    return (
      <div className="bg-white/10 backdrop-blur-lg rounded-2xl p-6 border border-white/20">
        <div className="flex items-center justify-center space-x-3">
          <Loader className="h-6 w-6 animate-spin text-blue-400" />
          <span className="text-white">Loading API keys from database...</span>
        </div>
      </div>
    );
  }

  if (!apiKeys) {
    return (
      <div className="bg-white/10 backdrop-blur-lg rounded-2xl p-6 border border-white/20">
        <div className="flex items-center space-x-3 mb-4">
          <AlertCircle className="h-6 w-6 text-red-400" />
          <span className="text-white font-semibold">API Keys Required</span>
        </div>
        <p className="text-gray-300 text-sm">
          Please configure your API keys in Settings to enable Tavus AI Avatar with Gemini 2.5 Flash integration.
        </p>
      </div>
    );
  }

  return (
    <div className="bg-white/10 backdrop-blur-lg rounded-2xl p-6 border border-white/20">
      {/* Header */}
      <div className="flex items-center justify-between mb-6">
        <div className="flex items-center space-x-3">
          <motion.div
            animate={{ 
              scale: avatarSpeaking ? [1, 1.1, 1] : 1,
              rotate: avatarSpeaking ? [0, 5, -5, 0] : 0
            }}
            transition={{ duration: 0.5, repeat: avatarSpeaking ? Infinity : 0 }}
            className="p-2 rounded-full bg-gradient-to-r from-purple-500 to-pink-500"
          >
            <Brain className="h-6 w-6 text-white" />
          </motion.div>
          <div>
            <h3 className="text-white font-semibold">Tavus AI Avatar (p5d11710002a)</h3>
            <div className="flex items-center space-x-2 text-sm">
              <div className={`w-2 h-2 rounded-full ${
                connectionStatus === 'connected' ? 'bg-green-400 animate-pulse' : 
                connectionStatus === 'connecting' ? 'bg-yellow-400 animate-pulse' : 
                connectionStatus === 'error' ? 'bg-red-400' : 'bg-gray-400'
              }`} />
              <span className="text-gray-300">
                {connectionStatus === 'connected' ? (avatarSpeaking ? 'Speaking...' : isListening ? 'Listening...' : 'Ready') :
                 connectionStatus === 'connecting' ? 'Connecting to Tavus + LiveKit...' :
                 connectionStatus === 'error' ? 'Connection Error' : 'Disconnected'}
              </span>
            </div>
          </div>
        </div>
        
        <div className="flex items-center space-x-2">
          {tavusSession && (
            <div className="text-xs text-green-300 flex items-center space-x-1">
              <CheckCircle className="h-3 w-3" />
              <span>Session: {tavusSession.conversation_id.slice(0, 8)}...</span>
            </div>
          )}
        </div>
      </div>

      {/* Connection Status */}
      {connectionStatus !== 'connected' && (
        <div className={`mb-4 p-4 rounded-lg border ${
          connectionStatus === 'error' ? 'bg-red-500/20 border-red-500/30' :
          connectionStatus === 'connecting' ? 'bg-yellow-500/20 border-yellow-500/30' :
          'bg-gray-500/20 border-gray-500/30'
        }`}>
          <div className="flex items-center space-x-2">
            {connectionStatus === 'connecting' && <Loader className="h-4 w-4 animate-spin text-yellow-400" />}
            {connectionStatus === 'error' && <AlertCircle className="h-4 w-4 text-red-400" />}
            {connectionStatus === 'disconnected' && <VideoOff className="h-4 w-4 text-gray-400" />}
            <span className={`text-sm font-medium ${
              connectionStatus === 'error' ? 'text-red-200' :
              connectionStatus === 'connecting' ? 'text-yellow-200' :
              'text-gray-200'
            }`}>
              {connectionStatus === 'connecting' ? 'Connecting to Tavus AI Avatar with p5d11710002a persona...' :
               connectionStatus === 'error' ? 'Failed to connect. Check API keys and try again.' :
               'Click to connect to Tavus AI Avatar'}
            </span>
          </div>
        </div>
      )}

      {/* API Status Indicators */}
      <div className="grid grid-cols-2 md:grid-cols-4 gap-3 mb-6">
        <div className="p-3 bg-black/20 rounded-lg">
          <div className="flex items-center space-x-2">
            <Brain className="h-4 w-4 text-purple-400" />
            <span className="text-xs text-white">Gemini 2.5</span>
          </div>
        </div>
        <div className="p-3 bg-black/20 rounded-lg">
          <div className="flex items-center space-x-2">
            <Video className="h-4 w-4 text-blue-400" />
            <span className="text-xs text-white">Tavus p5d11</span>
          </div>
        </div>
        <div className="p-3 bg-black/20 rounded-lg">
          <div className="flex items-center space-x-2">
            <Volume2 className="h-4 w-4 text-green-400" />
            <span className="text-xs text-white">
              {apiKeys.elevenlabs_api_key ? 'ElevenLabs' : 'Browser'}
            </span>
          </div>
        </div>
        <div className="p-3 bg-black/20 rounded-lg">
          <div className="flex items-center space-x-2">
            <Mic className="h-4 w-4 text-orange-400" />
            <span className="text-xs text-white">
              {apiKeys.deepgram_api_key ? 'Deepgram' : 'Browser'}
            </span>
          </div>
        </div>
      </div>

      {/* Video Feed */}
      {connectionStatus === 'connected' && (
        <div className="mb-6 relative">
          <div className="aspect-video bg-black rounded-lg overflow-hidden relative">
            {/* Tavus Avatar Video */}
            <video
              ref={avatarVideoRef}
              className="w-full h-full object-cover"
              autoPlay
              playsInline
            />
            
            {/* User Video (Picture-in-Picture) */}
            {isVideoEnabled && (
              <div className="absolute top-4 right-4 w-24 h-18 bg-gray-800 rounded-lg overflow-hidden">
                <video
                  ref={videoRef}
                  className="w-full h-full object-cover"
                  autoPlay
                  muted
                  playsInline
                />
              </div>
            )}
            
            {/* Speaking Indicator */}
            {avatarSpeaking && (
              <div className="absolute bottom-4 left-4 flex items-center space-x-2 bg-black/50 px-3 py-1 rounded-full">
                <motion.div
                  animate={{ scale: [1, 1.2, 1] }}
                  transition={{ duration: 0.5, repeat: Infinity }}
                  className="w-2 h-2 bg-green-400 rounded-full"
                />
                <span className="text-white text-sm">AI Speaking</span>
              </div>
            )}

            {/* Persona Indicator */}
            <div className="absolute top-4 left-4 bg-black/50 px-3 py-1 rounded-full">
              <span className="text-white text-xs font-medium">p5d11710002a</span>
            </div>
          </div>
          
          {/* Video Controls */}
          <div className="flex items-center justify-center space-x-4 mt-4">
            <button
              onClick={toggleVideo}
              className={`p-3 rounded-full transition-colors ${
                isVideoEnabled ? 'bg-blue-500 hover:bg-blue-600' : 'bg-gray-500 hover:bg-gray-600'
              }`}
            >
              {isVideoEnabled ? <Video className="h-5 w-5 text-white" /> : <VideoOff className="h-5 w-5 text-white" />}
            </button>
            
            <button
              onClick={toggleMute}
              className={`p-3 rounded-full transition-colors ${
                !isMuted ? 'bg-green-500 hover:bg-green-600' : 'bg-red-500 hover:bg-red-600'
              }`}
            >
              {!isMuted ? <Mic className="h-5 w-5 text-white" /> : <MicOff className="h-5 w-5 text-white" />}
            </button>
            
            <button
              onClick={isListening ? stopVoiceInput : startVoiceInput}
              className={`p-3 rounded-full transition-colors ${
                isListening ? 'bg-red-500 hover:bg-red-600 animate-pulse' : 'bg-purple-500 hover:bg-purple-600'
              }`}
            >
              {isListening ? <PhoneOff className="h-5 w-5 text-white" /> : <Phone className="h-5 w-5 text-white" />}
            </button>
          </div>
        </div>
      )}

      {/* Chat Interface */}
      <div className="bg-black/20 rounded-lg p-4 h-48 overflow-y-auto mb-4 space-y-3">
        {conversation.map((message) => (
          <motion.div
            key={message.id}
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className={`flex ${message.type === 'user' ? 'justify-end' : 'justify-start'}`}
          >
            <div className={`max-w-xs px-3 py-2 rounded-lg text-sm ${
              message.type === 'user' 
                ? 'bg-blue-500 text-white' 
                : 'bg-purple-500/80 text-white'
            }`}>
              {message.type === 'avatar' && (
                <div className="flex items-center space-x-1 mb-1">
                  <Heart className="h-3 w-3" />
                  <span className="text-xs font-medium">Tavus AI (p5d11710002a)</span>
                </div>
              )}
              <p>{message.content}</p>
              <p className="text-xs opacity-70 mt-1">
                {new Date(message.timestamp).toLocaleTimeString()}
              </p>
            </div>
          </motion.div>
        ))}
        <div ref={messagesEndRef} />
      </div>

      {/* Input Controls */}
      <div className="flex space-x-2">
        <input
          type="text"
          value={inputText}
          onChange={(e) => setInputText(e.target.value)}
          onKeyPress={(e) => e.key === 'Enter' && sendMessage()}
          placeholder="Chat with your Tavus AI avatar..."
          className="flex-1 px-4 py-2 bg-white/10 border border-white/20 rounded-lg text-white placeholder-gray-300 focus:outline-none focus:ring-2 focus:ring-purple-500"
        />
        <button
          onClick={sendMessage}
          disabled={!inputText.trim()}
          className="px-4 py-2 bg-purple-500 hover:bg-purple-600 disabled:opacity-50 text-white rounded-lg transition-colors"
        >
          Send
        </button>
      </div>

      {/* Technology Credits */}
      <div className="mt-4 text-xs text-gray-400 text-center space-y-1">
        <p>ü§ñ <strong>Tavus AI Avatar</strong> with persona p5d11710002a</p>
        <p>üß† Powered by <strong>Gemini 2.5 Flash</strong> for conversations</p>
        <p>üé• <strong>LiveKit</strong> for real-time video ‚Ä¢ üîä <strong>ElevenLabs</strong> voice</p>
        <p>üéôÔ∏è <strong>Deepgram</strong> speech recognition</p>
      </div>
    </div>
  );
}